{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_data(file_path, batch_size, sequence_size):\n",
    "    # Load data\n",
    "    with open(file_path) as file:\n",
    "        text = file.read().split()\n",
    "    \n",
    "    # Create support dictionaries\n",
    "    from collections import Counter as counter\n",
    "    \n",
    "    # Count how many times each word appears in the data\n",
    "    words_counter = counter(text)\n",
    "    \n",
    "    sorted_words = sorted(words_counter, key=words_counter.get, reverse=True)\n",
    "    \n",
    "    int_to_words = dict((indice, word) for indice, word in enumerate(sorted_words))\n",
    "    \n",
    "    words_to_int = dict((word, indice) for indice, word in int_to_words.items())\n",
    "    \n",
    "    number_of_words = len(int_to_words)\n",
    "    \n",
    "    # Generate network input, i.e words as integers\n",
    "    int_text = [words_to_int[word] for word in text]\n",
    "    \n",
    "    number_of_batchs = len(int_text) // (sequence_size * batch_size)\n",
    "    \n",
    "    # Remove one batch from the end of the list\n",
    "    batchs = int_text[:number_of_batchs * batch_size * sequence_size]\n",
    "    \n",
    "    # Generate network input target, the target of each input,\n",
    "    # in text generation, its the consecutive input\n",
    "    # \n",
    "    # To obtain the target its necessary to shift all values one\n",
    "    # step to the left\n",
    "    labels = numpy.zeros_like(batchs)\n",
    "    \n",
    "    try:\n",
    "        # Shift all values to the left\n",
    "        labels[:-1] = batchs[1:]\n",
    "\n",
    "        # Set the next word of the last value of the last list to the\n",
    "        # first value of the first list\n",
    "        labels[-1] = batchs[0]\n",
    "\n",
    "        labels = numpy.reshape(labels, (batch_size, -1))\n",
    "\n",
    "        batchs = numpy.reshape(batchs, (batch_size, -1))\n",
    "    except IndexError as error:\n",
    "        raise Exception('Invalid amount of words to generate the batchs / sequences')\n",
    "    \n",
    "    return dict(\n",
    "        int_to_words=int_to_words,\n",
    "        words_to_int=words_to_int,\n",
    "        batchs=batchs,\n",
    "        labels=labels,\n",
    "        number_of_words=number_of_words\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def getBatchs(batch, labels, batch_size, sequence_size):\n",
    "    numBatchs = numpy.prod(batch.shape) // (sequence_size * batch_size)\n",
    "    \n",
    "    for indice in range(0, numBatchs * sequence_size, sequence_size):\n",
    "        yield batch[:, indice:indice + sequence_size], labels[:, indice:indice + sequence_size]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, number_of_words, sequence_size, embedding_size, lstm_size):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.sequence_size = sequence_size\n",
    "\n",
    "        self.lstm_size = lstm_size\n",
    "\n",
    "        self.embedding = nn.Embedding(number_of_words, embedding_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_size,\n",
    "            lstm_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Linear(lstm_size, number_of_words)\n",
    "\n",
    "    def forward(self, state, previous_state):\n",
    "        embed = self.embedding(state)\n",
    "\n",
    "        output, state = self.lstm(embed, previous_state)\n",
    "\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def resetState(self, batchSize):\n",
    "        # Reset the hidden (h) state and the memory (c) state\n",
    "        return (torch.zeros(1, batchSize, self.lstm_size) for indice in range(2))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "sequence_size = 32\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "embedding_size = 64\n",
    "\n",
    "lstm_size = 64\n",
    "\n",
    "cuda = False\n",
    "\n",
    "epochs = 14\n",
    "\n",
    "learn_rating = 0.1\n",
    "\n",
    "gradients_norm = 5\n",
    "\n",
    "initial_words = ['I', 'think', 'life', 'is']\n",
    "\n",
    "top = 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data = load_data('data.raw', batch_size, sequence_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = LSTM(\n",
    "    data.get('number_of_words'),\n",
    "    sequence_size,\n",
    "    embedding_size,\n",
    "    lstm_size\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available and cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learn_rating)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "iteration = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def predict(model, initial_words, number_of_words, words_to_int, int_to_words, top=5):\n",
    "    # Set evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    words = initial_words.copy()\n",
    "\n",
    "    # Reset state\n",
    "    stateHidden, stateMemory = model.resetState(1)\n",
    "\n",
    "    if torch.cuda.is_available and cuda:\n",
    "        stateHidden, stateMemory = stateHidden.cuda(), stateMemory.cuda()\n",
    "\n",
    "    for word in words:\n",
    "        _word = torch.tensor([[words_to_int[word]]])\n",
    "\n",
    "        if torch.cuda.is_available and cuda:\n",
    "            _word = _word.cuda()\n",
    "\n",
    "        output, (stateHidden, stateMemory) = model(\n",
    "            _word,\n",
    "            (stateHidden, stateMemory)\n",
    "        )\n",
    "\n",
    "    _, _top = torch.topk(output[0], k=top)\n",
    "\n",
    "    choices = _top.tolist()\n",
    "\n",
    "    choice = numpy.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_words[choice])\n",
    "\n",
    "    for _ in range(100):\n",
    "        _word = torch.tensor([[choice]])\n",
    "\n",
    "        if torch.cuda.is_available and cuda:\n",
    "            _word = _word.cuda()\n",
    "\n",
    "        output, (stateHidden, stateMemory) = model(\n",
    "            _word,\n",
    "            (stateHidden, stateMemory)\n",
    "        )\n",
    "\n",
    "        _, _top = torch.topk(output[0], k=top)\n",
    "\n",
    "        choices = _top.tolist()\n",
    "\n",
    "        choice = numpy.random.choice(choices[0])\n",
    "\n",
    "        words.append(int_to_words[choice])\n",
    "\n",
    "    print(' '.join(words).encode('utf-8'))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for epoch in range(epochs):\n",
    "    batchs = getBatchs(\n",
    "        data.get('batchs'),\n",
    "        data.get('labels'),\n",
    "        batch_size,\n",
    "        sequence_size\n",
    "    )\n",
    "    \n",
    "    stateHidden, stateMemory = model.resetState(batch_size)\n",
    "    \n",
    "    if torch.cuda.is_available and cuda:\n",
    "        stateHidden, stateMemory = stateHidden.cuda(), stateMemory.cuda()\n",
    "            \n",
    "    for batch_data, batch_label in batchs:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Set train mode\n",
    "        model.train()\n",
    "        \n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Transform array to tensor\n",
    "        batch_data = torch.tensor(batch_data)\n",
    "        \n",
    "        batch_label = torch.tensor(batch_label)\n",
    "        \n",
    "        # Send tensor to GPU\n",
    "        if torch.cuda.is_available and cuda:\n",
    "            batch_data = batch_data.cuda()\n",
    "            \n",
    "            batch_label = batch_label.cuda()\n",
    "        \n",
    "        # Train\n",
    "        logits, (stateHidden, stateMemory) = model(\n",
    "            batch_data,\n",
    "            (stateHidden, stateMemory)\n",
    "        )\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(logits.transpose(1, 2), batch_label)\n",
    "        \n",
    "        # Remove state from graph for gradient clipping\n",
    "        stateHidden = stateHidden.detach()\n",
    "        \n",
    "        stateMemory = stateMemory.detach()\n",
    "        \n",
    "        # Back-propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (inline)\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            model.parameters(),\n",
    "            gradients_norm\n",
    "        )\n",
    "        \n",
    "        # Update network's parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Loss value\n",
    "        print(f'Epoch {epoch}, Iteration: {iteration}, Loss: {loss.item()}')\n",
    "        \n",
    "        # Predict value\n",
    "        if iteration % 20 == 0:\n",
    "            predict(model, initial_words, data.get('number_of_words'), data.get('words_to_int'), data.get('int_to_words'), top)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0, Iteration: 1, Loss: 8.65025520324707\n",
      "Epoch 0, Iteration: 2, Loss: 8.3564453125\n",
      "Epoch 0, Iteration: 3, Loss: 8.264205932617188\n",
      "Epoch 0, Iteration: 4, Loss: 7.507660865783691\n",
      "Epoch 0, Iteration: 5, Loss: 7.194112777709961\n",
      "Epoch 0, Iteration: 6, Loss: 7.409313678741455\n",
      "Epoch 0, Iteration: 7, Loss: 7.552872657775879\n",
      "Epoch 0, Iteration: 8, Loss: 7.43687629699707\n",
      "Epoch 0, Iteration: 9, Loss: 7.4203877449035645\n",
      "Epoch 0, Iteration: 10, Loss: 7.384235858917236\n",
      "Epoch 0, Iteration: 11, Loss: 7.565990924835205\n",
      "Epoch 0, Iteration: 12, Loss: 7.666876792907715\n",
      "Epoch 0, Iteration: 13, Loss: 7.5550312995910645\n",
      "Epoch 0, Iteration: 14, Loss: 7.284774303436279\n",
      "Epoch 0, Iteration: 15, Loss: 7.402453899383545\n",
      "Epoch 0, Iteration: 16, Loss: 7.411348342895508\n",
      "Epoch 0, Iteration: 17, Loss: 7.311158180236816\n",
      "Epoch 0, Iteration: 18, Loss: 7.591379165649414\n",
      "Epoch 0, Iteration: 19, Loss: 7.241386413574219\n",
      "Epoch 0, Iteration: 20, Loss: 7.4343061447143555\n",
      "b\"I guess. INT. SEBASTIAN'S DECKARD'S Japanese) sign He sits wall. the of the INT. SEBASTIAN'S wad second a little INT. BRYANT'S of the INT. GAFF - NIGHT of a little more test and the INT. ROOF to TO INT. sergeant is of the way of the INT. - is room in his and he Kampff uni- He opens is is Deckard doesn't into his of the INT. DECKARD'S Japanese) Bryant choking in his as he Kampff GAFF ROOF of he Kampff tiny second the elevator NIGHT Deckard stares a this of it. He doesn't the way is and his and for his\"\n",
      "Epoch 0, Iteration: 21, Loss: 7.097557067871094\n",
      "Epoch 0, Iteration: 22, Loss: 7.586811542510986\n",
      "Epoch 0, Iteration: 23, Loss: 7.656683444976807\n",
      "Epoch 0, Iteration: 24, Loss: 7.616062641143799\n",
      "Epoch 0, Iteration: 25, Loss: 7.745707035064697\n",
      "Epoch 0, Iteration: 26, Loss: 7.8734235763549805\n",
      "Epoch 0, Iteration: 27, Loss: 7.509536266326904\n",
      "Epoch 0, Iteration: 28, Loss: 7.421060562133789\n",
      "Epoch 0, Iteration: 29, Loss: 7.528722286224365\n",
      "Epoch 0, Iteration: 30, Loss: 7.234058380126953\n",
      "Epoch 0, Iteration: 31, Loss: 7.3662309646606445\n",
      "Epoch 0, Iteration: 32, Loss: 7.479831218719482\n",
      "Epoch 0, Iteration: 33, Loss: 7.742480278015137\n",
      "Epoch 0, Iteration: 34, Loss: 7.413846492767334\n",
      "Epoch 0, Iteration: 35, Loss: 7.001354694366455\n",
      "Epoch 0, Iteration: 36, Loss: 7.535711765289307\n",
      "Epoch 0, Iteration: 37, Loss: 7.142085075378418\n",
      "Epoch 0, Iteration: 38, Loss: 7.385101795196533\n",
      "Epoch 0, Iteration: 39, Loss: 7.043463706970215\n",
      "Epoch 0, Iteration: 40, Loss: 7.404044151306152\n",
      "b\"I don't get the spinner is and the and the and is the same like is the same old TO: - I was around and The INT. CORRIDOR - and The INT. CORRIDOR SEBASTIAN The BATTY the and the spinner and looks and the of his eyes CUT Pris the and is Gaff of I guess a way is the door at a have You think SEBASTIAN on his CUT TO INT. CORRIDOR SEBASTIAN and Deckard gets up a strange room looks the door like to TO: - the and Deckard and out of this is Gaff the same like is the\"\n",
      "Epoch 0, Iteration: 41, Loss: 7.02143669128418\n",
      "Epoch 1, Iteration: 42, Loss: 6.673555374145508\n",
      "Epoch 1, Iteration: 43, Loss: 6.48204231262207\n",
      "Epoch 1, Iteration: 44, Loss: 6.616971015930176\n",
      "Epoch 1, Iteration: 45, Loss: 6.488169193267822\n",
      "Epoch 1, Iteration: 46, Loss: 6.392221927642822\n",
      "Epoch 1, Iteration: 47, Loss: 6.325494766235352\n",
      "Epoch 1, Iteration: 48, Loss: 6.368237018585205\n",
      "Epoch 1, Iteration: 49, Loss: 6.468302249908447\n",
      "Epoch 1, Iteration: 50, Loss: 6.4641194343566895\n",
      "Epoch 1, Iteration: 51, Loss: 6.265958786010742\n",
      "Epoch 1, Iteration: 52, Loss: 6.414993762969971\n",
      "Epoch 1, Iteration: 53, Loss: 6.432334899902344\n",
      "Epoch 1, Iteration: 54, Loss: 6.450534343719482\n",
      "Epoch 1, Iteration: 55, Loss: 6.099899768829346\n",
      "Epoch 1, Iteration: 56, Loss: 6.355473041534424\n",
      "Epoch 1, Iteration: 57, Loss: 6.107097148895264\n",
      "Epoch 1, Iteration: 58, Loss: 6.2741193771362305\n",
      "Epoch 1, Iteration: 59, Loss: 6.35945987701416\n",
      "Epoch 1, Iteration: 60, Loss: 6.029777526855469\n",
      "b\"I wouldn't in an alteration is looking down on the floor. him in her you to Deckard turns the picture of it. TYRELL on my the picture to be a and a The Counterman is the floor. DECKARD (O.S.) The a on his blaster ready. INT. SEBASTIAN'S APARTMENT DECKARD You in the wall. RACHAEL I got a in the window, He sits LIVING THE and and the floor. in front on a in the window, as they DECKARD You the Tyrell Corporation of the picture DECKARD I am to a on her and into a on her and he and into her\"\n",
      "Epoch 1, Iteration: 61, Loss: 6.314227104187012\n",
      "Epoch 1, Iteration: 62, Loss: 5.9824748039245605\n",
      "Epoch 1, Iteration: 63, Loss: 6.313273906707764\n",
      "Epoch 1, Iteration: 64, Loss: 6.437028408050537\n",
      "Epoch 1, Iteration: 65, Loss: 6.347940444946289\n",
      "Epoch 1, Iteration: 66, Loss: 6.4456377029418945\n",
      "Epoch 1, Iteration: 67, Loss: 6.648674964904785\n",
      "Epoch 1, Iteration: 68, Loss: 6.32347297668457\n",
      "Epoch 1, Iteration: 69, Loss: 6.285346031188965\n",
      "Epoch 1, Iteration: 70, Loss: 6.323826313018799\n",
      "Epoch 1, Iteration: 71, Loss: 6.006899833679199\n",
      "Epoch 1, Iteration: 72, Loss: 6.238266944885254\n",
      "Epoch 1, Iteration: 73, Loss: 6.2288126945495605\n",
      "Epoch 1, Iteration: 74, Loss: 6.354213237762451\n",
      "Epoch 1, Iteration: 75, Loss: 6.044643878936768\n",
      "Epoch 1, Iteration: 76, Loss: 5.665520668029785\n",
      "Epoch 1, Iteration: 77, Loss: 6.158726692199707\n",
      "Epoch 1, Iteration: 78, Loss: 6.026023864746094\n",
      "Epoch 1, Iteration: 79, Loss: 6.126772880554199\n",
      "Epoch 1, Iteration: 80, Loss: 6.023902416229248\n",
      "b\"I thought think too looks to a room looks is standing on a little smile in front on me, the door is suddenly have the elevator CHEW a little little smile is a snake I was being doorway Lots of the room looks TO A voice hesitates, more drops Deckard and Sebastian is standing of your to be and puts to be CUT The the passenger Pris on and Gaff on Deckard looks and Gaff glares back to Deckard. DECKARD I'm to Deckard. He comes SEBASTIAN out one of your old the of this voice head, - NIGHT the is suddenly SEBASTIAN\"\n",
      "Epoch 1, Iteration: 81, Loss: 6.24293851852417\n",
      "Epoch 1, Iteration: 82, Loss: 5.991374969482422\n",
      "Epoch 2, Iteration: 83, Loss: 5.894586563110352\n",
      "Epoch 2, Iteration: 84, Loss: 5.744094371795654\n",
      "Epoch 2, Iteration: 85, Loss: 5.903741836547852\n",
      "Epoch 2, Iteration: 86, Loss: 5.707459449768066\n",
      "Epoch 2, Iteration: 87, Loss: 5.671135902404785\n",
      "Epoch 2, Iteration: 88, Loss: 5.7512898445129395\n",
      "Epoch 2, Iteration: 89, Loss: 5.793090343475342\n",
      "Epoch 2, Iteration: 90, Loss: 5.88259220123291\n",
      "Epoch 2, Iteration: 91, Loss: 5.759493827819824\n",
      "Epoch 2, Iteration: 92, Loss: 5.540400981903076\n",
      "Epoch 2, Iteration: 93, Loss: 5.81832218170166\n",
      "Epoch 2, Iteration: 94, Loss: 5.751492977142334\n",
      "Epoch 2, Iteration: 95, Loss: 5.732314586639404\n",
      "Epoch 2, Iteration: 96, Loss: 5.423053741455078\n",
      "Epoch 2, Iteration: 97, Loss: 5.6501784324646\n",
      "Epoch 2, Iteration: 98, Loss: 5.374015808105469\n",
      "Epoch 2, Iteration: 99, Loss: 5.645956039428711\n",
      "Epoch 2, Iteration: 100, Loss: 5.627283096313477\n",
      "b\"I don't do as he and he is looking Batty to a room and a snake a room is standing on it to the door and holds the wall of it. Deckard steps the wall. The the apartment. the wall. see Deckard doesn't know. the wall in his head of her eyes of an impression into a snake NIGHT An hands behind her hand is looking at his pocket and the distance. EXT. STREETS as his hands the room for a room and a long night the shadows on it to Deckard doesn't like his hands The CLOCK TICKS. it and his\"\n",
      "Epoch 2, Iteration: 101, Loss: 5.388772487640381\n",
      "Epoch 2, Iteration: 102, Loss: 5.528948783874512\n",
      "Epoch 2, Iteration: 103, Loss: 5.309132099151611\n",
      "Epoch 2, Iteration: 104, Loss: 5.5899457931518555\n",
      "Epoch 2, Iteration: 105, Loss: 5.618191719055176\n",
      "Epoch 2, Iteration: 106, Loss: 5.6816511154174805\n",
      "Epoch 2, Iteration: 107, Loss: 5.753819942474365\n",
      "Epoch 2, Iteration: 108, Loss: 5.767453670501709\n",
      "Epoch 2, Iteration: 109, Loss: 5.587710380554199\n",
      "Epoch 2, Iteration: 110, Loss: 5.418641090393066\n",
      "Epoch 2, Iteration: 111, Loss: 5.52992582321167\n",
      "Epoch 2, Iteration: 112, Loss: 5.475131511688232\n",
      "Epoch 2, Iteration: 113, Loss: 5.4377641677856445\n",
      "Epoch 2, Iteration: 114, Loss: 5.479948997497559\n",
      "Epoch 2, Iteration: 115, Loss: 5.601522922515869\n",
      "Epoch 2, Iteration: 116, Loss: 5.298579216003418\n",
      "Epoch 2, Iteration: 117, Loss: 5.056010723114014\n",
      "Epoch 2, Iteration: 118, Loss: 5.315332889556885\n",
      "Epoch 2, Iteration: 119, Loss: 5.260793685913086\n",
      "Epoch 2, Iteration: 120, Loss: 5.374281406402588\n",
      "b\"I wouldn't would me, CUT TO INT. SPINNER INT. SPINNER ROOM VIEW VIEW VIEW VIEW to a run and puts and the elevator Pris looks around face and the side as Deckard is staring the elevator just a long moment. DECKARD Ya hospital on, Gaff. Deckard is standing in his eyes have to a lot of his head is staring at Tyrell. The CLOCK on their little holding into him. Deckard comes down her moment it is. in front to climb He starts into him. Deckard punches the elevator hums Deckard looks startled. and starts female. around him. The the same one,\"\n",
      "Epoch 2, Iteration: 121, Loss: 5.3111090660095215\n",
      "Epoch 2, Iteration: 122, Loss: 5.453352928161621\n",
      "Epoch 2, Iteration: 123, Loss: 5.234695911407471\n",
      "Epoch 3, Iteration: 124, Loss: 5.273797512054443\n",
      "Epoch 3, Iteration: 125, Loss: 5.2023725509643555\n",
      "Epoch 3, Iteration: 126, Loss: 5.384122848510742\n",
      "Epoch 3, Iteration: 127, Loss: 5.173973083496094\n",
      "Epoch 3, Iteration: 128, Loss: 5.060129642486572\n",
      "Epoch 3, Iteration: 129, Loss: 5.233593463897705\n",
      "Epoch 3, Iteration: 130, Loss: 5.309350490570068\n",
      "Epoch 3, Iteration: 131, Loss: 5.275064945220947\n",
      "Epoch 3, Iteration: 132, Loss: 5.242824554443359\n",
      "Epoch 3, Iteration: 133, Loss: 5.083306789398193\n",
      "Epoch 3, Iteration: 134, Loss: 5.2782301902771\n",
      "Epoch 3, Iteration: 135, Loss: 5.302165508270264\n",
      "Epoch 3, Iteration: 136, Loss: 5.283050060272217\n",
      "Epoch 3, Iteration: 137, Loss: 5.053684711456299\n",
      "Epoch 3, Iteration: 138, Loss: 5.1034040451049805\n",
      "Epoch 3, Iteration: 139, Loss: 4.85420036315918\n",
      "Epoch 3, Iteration: 140, Loss: 5.1646342277526855\n",
      "b\"I don't think I want you. DECKARD I don't think I'm DECKARD No. of a long hard again, home her furious on his shoulder. Deckard steps at the man is standing a long hard again, RACHAEL (OS) The room with my looking at the floor. His eyes is sitting the wall of an unnatural look. Deckard doesn't a series Deckard is sitting on a little holding it with him. Batty doesn't understand the picture passes the floor. it. He levels the big an escape on a picture on her hand and he and he feels and his blaster I was the man\"\n",
      "Epoch 3, Iteration: 141, Loss: 5.11760950088501\n",
      "Epoch 3, Iteration: 142, Loss: 5.033802032470703\n",
      "Epoch 3, Iteration: 143, Loss: 5.089715957641602\n",
      "Epoch 3, Iteration: 144, Loss: 4.800546646118164\n",
      "Epoch 3, Iteration: 145, Loss: 5.045347690582275\n",
      "Epoch 3, Iteration: 146, Loss: 5.139707088470459\n",
      "Epoch 3, Iteration: 147, Loss: 5.223354339599609\n",
      "Epoch 3, Iteration: 148, Loss: 5.135815143585205\n",
      "Epoch 3, Iteration: 149, Loss: 5.179296016693115\n",
      "Epoch 3, Iteration: 150, Loss: 5.105172157287598\n",
      "Epoch 3, Iteration: 151, Loss: 5.034168720245361\n",
      "Epoch 3, Iteration: 152, Loss: 5.050360202789307\n",
      "Epoch 3, Iteration: 153, Loss: 4.944220066070557\n",
      "Epoch 3, Iteration: 154, Loss: 4.973605155944824\n",
      "Epoch 3, Iteration: 155, Loss: 5.005411148071289\n",
      "Epoch 3, Iteration: 156, Loss: 5.103591442108154\n",
      "Epoch 3, Iteration: 157, Loss: 4.81051778793335\n",
      "Epoch 3, Iteration: 158, Loss: 4.6834492683410645\n",
      "Epoch 3, Iteration: 159, Loss: 4.823216438293457\n",
      "Epoch 3, Iteration: 160, Loss: 4.730274200439453\n",
      "b\"I don't understand and a little sparkle. a smile totally What I don't know So and a smile of my Decision time. CUT TO: INT. POLICE HQ CONCOURSE SEBASTIAN You replicant! his own Deckard looks at the door into your mother. a little the spinner slides toward a long silence. GAFF What you ? A spinner slides that reflects of my vid-screen) in the passenger feet stepping you are. like the passenger than all. What generation is staring on its the elevator is staring into a long silence. GAFF You have dix snake ... he brings a few of a lot of\"\n",
      "Epoch 3, Iteration: 161, Loss: 5.0834221839904785\n",
      "Epoch 3, Iteration: 162, Loss: 4.98727560043335\n",
      "Epoch 3, Iteration: 163, Loss: 5.000159740447998\n",
      "Epoch 3, Iteration: 164, Loss: 4.820861339569092\n",
      "Epoch 4, Iteration: 165, Loss: 4.841378688812256\n",
      "Epoch 4, Iteration: 166, Loss: 4.807540416717529\n",
      "Epoch 4, Iteration: 167, Loss: 4.951705455780029\n",
      "Epoch 4, Iteration: 168, Loss: 4.668998718261719\n",
      "Epoch 4, Iteration: 169, Loss: 4.676054954528809\n",
      "Epoch 4, Iteration: 170, Loss: 4.910052299499512\n",
      "Epoch 4, Iteration: 171, Loss: 4.873951435089111\n",
      "Epoch 4, Iteration: 172, Loss: 4.81073522567749\n",
      "Epoch 4, Iteration: 173, Loss: 5.012876510620117\n",
      "Epoch 4, Iteration: 174, Loss: 4.80417013168335\n",
      "Epoch 4, Iteration: 175, Loss: 4.963032245635986\n",
      "Epoch 4, Iteration: 176, Loss: 4.9712910652160645\n",
      "Epoch 4, Iteration: 177, Loss: 4.852197170257568\n",
      "Epoch 4, Iteration: 178, Loss: 4.785826206207275\n",
      "Epoch 4, Iteration: 179, Loss: 4.782840728759766\n",
      "Epoch 4, Iteration: 180, Loss: 4.643141746520996\n",
      "b\"I want to a big guy is a long silence whilst through. studies his face. Deckard is is the bed in front Deckard steps on her and looks like a couple on his face. Deckard doesn't know. one. I take a big an easy man it on an impression in her furious feet. the dark near the room with a couple of a couple it on the wall over his head and a big screen in the shadows. Deckard's his head in his face. DECKARD Take in his pocket and he and a huge bed mutering and a little holding in the\"\n",
      "Epoch 4, Iteration: 181, Loss: 4.918643951416016\n",
      "Epoch 4, Iteration: 182, Loss: 4.780811309814453\n",
      "Epoch 4, Iteration: 183, Loss: 4.785118103027344\n",
      "Epoch 4, Iteration: 184, Loss: 4.767991542816162\n",
      "Epoch 4, Iteration: 185, Loss: 4.576826572418213\n",
      "Epoch 4, Iteration: 186, Loss: 4.744078636169434\n",
      "Epoch 4, Iteration: 187, Loss: 4.870476722717285\n",
      "Epoch 4, Iteration: 188, Loss: 4.998899459838867\n",
      "Epoch 4, Iteration: 189, Loss: 4.93705415725708\n",
      "Epoch 4, Iteration: 190, Loss: 4.956905841827393\n",
      "Epoch 4, Iteration: 191, Loss: 4.836237907409668\n",
      "Epoch 4, Iteration: 192, Loss: 4.650993347167969\n",
      "Epoch 4, Iteration: 193, Loss: 4.842342376708984\n",
      "Epoch 4, Iteration: 194, Loss: 4.804553031921387\n",
      "Epoch 4, Iteration: 195, Loss: 4.717219352722168\n",
      "Epoch 4, Iteration: 196, Loss: 4.655148029327393\n",
      "Epoch 4, Iteration: 197, Loss: 4.826936721801758\n",
      "Epoch 4, Iteration: 198, Loss: 4.60062313079834\n",
      "Epoch 4, Iteration: 199, Loss: 4.445627689361572\n",
      "Epoch 4, Iteration: 200, Loss: 4.520578384399414\n",
      "b\"I don't have seen the room darkens. then around the door in the passenger needs! place. SALOME DECKARD There's only over and a long moment with a couple of Chews's looking down the side and pulls his hands starts running out a couple of the same go on. CUT breathing is standing the door opens. Deckard is staring up the passenger seat, still says with a little shaken. Capillary dilation makes a few moments, Rachael? don't look the side and a lot that's all. of his attention the passenger seat, in front of your tailor? look it is looking the edge BATTY\"\n",
      "Epoch 4, Iteration: 201, Loss: 4.447170257568359\n",
      "Epoch 4, Iteration: 202, Loss: 4.820516586303711\n",
      "Epoch 4, Iteration: 203, Loss: 4.794022560119629\n",
      "Epoch 4, Iteration: 204, Loss: 4.725605010986328\n",
      "Epoch 4, Iteration: 205, Loss: 4.527156352996826\n",
      "Epoch 5, Iteration: 206, Loss: 4.633845329284668\n",
      "Epoch 5, Iteration: 207, Loss: 4.679293155670166\n",
      "Epoch 5, Iteration: 208, Loss: 4.61109733581543\n",
      "Epoch 5, Iteration: 209, Loss: 4.436222553253174\n",
      "Epoch 5, Iteration: 210, Loss: 4.487805366516113\n",
      "Epoch 5, Iteration: 211, Loss: 4.677135467529297\n",
      "Epoch 5, Iteration: 212, Loss: 4.791408061981201\n",
      "Epoch 5, Iteration: 213, Loss: 4.6953301429748535\n",
      "Epoch 5, Iteration: 214, Loss: 4.8690361976623535\n",
      "Epoch 5, Iteration: 215, Loss: 4.5674920082092285\n",
      "Epoch 5, Iteration: 216, Loss: 4.742563724517822\n",
      "Epoch 5, Iteration: 217, Loss: 4.829237937927246\n",
      "Epoch 5, Iteration: 218, Loss: 4.790671348571777\n",
      "Epoch 5, Iteration: 219, Loss: 4.669900417327881\n",
      "Epoch 5, Iteration: 220, Loss: 4.512659549713135\n",
      "b\"I want you. DECKARD I don't want... He can count! of the floor. Deckard steps aside, woman back in his hand to a couple She's alive. door with her side, a few Back.... (whirr) automation. he grovels, he's not far it is sitting at Batty and a little tinfoil Cautiously around eyes Batty doesn't understand an invitation. her look, doesnt Zhora, in front DECKARD I am acting off. Deckard looks back for his hand and his hand back. DECKARD No. You Nexus? of a huge pyramid not her. Buzz already flames DECKARD You have things The view an official he kisses the\"\n",
      "Epoch 5, Iteration: 221, Loss: 4.566945552825928\n",
      "Epoch 5, Iteration: 222, Loss: 4.7172722816467285\n",
      "Epoch 5, Iteration: 223, Loss: 4.653716564178467\n",
      "Epoch 5, Iteration: 224, Loss: 4.679888725280762\n",
      "Epoch 5, Iteration: 225, Loss: 4.623007297515869\n",
      "Epoch 5, Iteration: 226, Loss: 4.558900356292725\n",
      "Epoch 5, Iteration: 227, Loss: 4.679922580718994\n",
      "Epoch 5, Iteration: 228, Loss: 4.637888431549072\n",
      "Epoch 5, Iteration: 229, Loss: 4.75258731842041\n",
      "Epoch 5, Iteration: 230, Loss: 4.760576248168945\n",
      "Epoch 5, Iteration: 231, Loss: 4.69930362701416\n",
      "Epoch 5, Iteration: 232, Loss: 4.702830791473389\n",
      "Epoch 5, Iteration: 233, Loss: 4.603391647338867\n",
      "Epoch 5, Iteration: 234, Loss: 4.69004487991333\n",
      "Epoch 5, Iteration: 235, Loss: 4.639379978179932\n",
      "Epoch 5, Iteration: 236, Loss: 4.637877941131592\n",
      "Epoch 5, Iteration: 237, Loss: 4.546951770782471\n",
      "Epoch 5, Iteration: 238, Loss: 4.56854248046875\n",
      "Epoch 5, Iteration: 239, Loss: 4.237555980682373\n",
      "Epoch 5, Iteration: 240, Loss: 4.37742280960083\n",
      "b\"I guess I wouldn't let the door and starts to his head. Thunder comes out and looks stoned and a little people. GAFF But Leon is suddenly BATTY Questions! RRRRRIIIIIIPPPP.Batty starts through his head. Deckard punches the picture DECKARD You got a lot of his footfalls It's Pris. Now doesn't say anything. my Kampff test...... heat, it on the side of enticement the street. Then we might pick down on a few years face. slow shot. legs... a long silence. BATTY Morphology.. wouldn't PRIS Oh! touches Holden and puts the room with his hands looks down the edge Deckard punches it and\"\n",
      "Epoch 5, Iteration: 241, Loss: 4.528964042663574\n",
      "Epoch 5, Iteration: 242, Loss: 4.363210678100586\n",
      "Epoch 5, Iteration: 243, Loss: 4.644382953643799\n",
      "Epoch 5, Iteration: 244, Loss: 4.640187740325928\n",
      "Epoch 5, Iteration: 245, Loss: 4.600447654724121\n",
      "Epoch 5, Iteration: 246, Loss: 4.426315784454346\n",
      "Epoch 6, Iteration: 247, Loss: 4.448263168334961\n",
      "Epoch 6, Iteration: 248, Loss: 4.517911911010742\n",
      "Epoch 6, Iteration: 249, Loss: 4.486721992492676\n",
      "Epoch 6, Iteration: 250, Loss: 4.390851974487305\n",
      "Epoch 6, Iteration: 251, Loss: 4.46519660949707\n",
      "Epoch 6, Iteration: 252, Loss: 4.658775806427002\n",
      "Epoch 6, Iteration: 253, Loss: 4.485637664794922\n",
      "Epoch 6, Iteration: 254, Loss: 4.501086711883545\n",
      "Epoch 6, Iteration: 255, Loss: 4.720831394195557\n",
      "Epoch 6, Iteration: 256, Loss: 4.468042373657227\n",
      "Epoch 6, Iteration: 257, Loss: 4.448198318481445\n",
      "Epoch 6, Iteration: 258, Loss: 4.590756893157959\n",
      "Epoch 6, Iteration: 259, Loss: 4.658867835998535\n",
      "Epoch 6, Iteration: 260, Loss: 4.390788555145264\n",
      "b\"I don't know. She's advancing as his shoulder. He can count! escape. about friends? one shot. could He knows in a few we might eat Bryant's me? block me? landscape can't have things MORNING got a few key physical. human He's sitting and the spinner I got it is the wall in her is looking at the Tyrell on her furious - DUSK bar and looks around. DECKARD Please! Very thought. her embrace. turns and looks up the shadows. DECKARD The BABY soft. She's watching. The spinner I don't pictures. him. Batty is the Tyrell and he can to Deckard. DECKARD The\"\n",
      "Epoch 6, Iteration: 261, Loss: 4.481729984283447\n",
      "Epoch 6, Iteration: 262, Loss: 4.3922529220581055\n",
      "Epoch 6, Iteration: 263, Loss: 4.556608200073242\n",
      "Epoch 6, Iteration: 264, Loss: 4.541335105895996\n",
      "Epoch 6, Iteration: 265, Loss: 4.417968273162842\n",
      "Epoch 6, Iteration: 266, Loss: 4.459803104400635\n",
      "Epoch 6, Iteration: 267, Loss: 4.427691459655762\n",
      "Epoch 6, Iteration: 268, Loss: 4.470713138580322\n",
      "Epoch 6, Iteration: 269, Loss: 4.376173496246338\n",
      "Epoch 6, Iteration: 270, Loss: 4.6189866065979\n",
      "Epoch 6, Iteration: 271, Loss: 4.470706462860107\n",
      "Epoch 6, Iteration: 272, Loss: 4.637548923492432\n",
      "Epoch 6, Iteration: 273, Loss: 4.571159839630127\n",
      "Epoch 6, Iteration: 274, Loss: 4.3208417892456055\n",
      "Epoch 6, Iteration: 275, Loss: 4.510036945343018\n",
      "Epoch 6, Iteration: 276, Loss: 4.659553527832031\n",
      "Epoch 6, Iteration: 277, Loss: 4.620358943939209\n",
      "Epoch 6, Iteration: 278, Loss: 4.384833335876465\n",
      "Epoch 6, Iteration: 279, Loss: 4.525780200958252\n",
      "Epoch 6, Iteration: 280, Loss: 4.207670211791992\n",
      "b\"I wouldn't fool you're through, look the door and starts to the edge with BATTY Ah! Sebastian. DECKARD I wouldn't it to be a few are not computers, through the spinner lifts well tailored no goddamn different are looking at the other door leading in his pocket on its gloomy when you look better. CHEW (desperate) Just better. She pauses DECKARD Why ? TYRELL CORP. do the living But no, Gaff's the spinner voice and starts punching him ? TYRELL He is a series It has to the edge of the door and puts Holden starts toward you see later I wouldn't\"\n",
      "Epoch 6, Iteration: 281, Loss: 4.259038925170898\n",
      "Epoch 6, Iteration: 282, Loss: 4.3564863204956055\n",
      "Epoch 6, Iteration: 283, Loss: 4.231975555419922\n",
      "Epoch 6, Iteration: 284, Loss: 4.341264247894287\n",
      "Epoch 6, Iteration: 285, Loss: 4.468113899230957\n",
      "Epoch 6, Iteration: 286, Loss: 4.395585536956787\n",
      "Epoch 6, Iteration: 287, Loss: 4.178511619567871\n",
      "Epoch 7, Iteration: 288, Loss: 4.4090256690979\n",
      "Epoch 7, Iteration: 289, Loss: 4.291813850402832\n",
      "Epoch 7, Iteration: 290, Loss: 4.346138954162598\n",
      "Epoch 7, Iteration: 291, Loss: 4.177186965942383\n",
      "Epoch 7, Iteration: 292, Loss: 4.235351085662842\n",
      "Epoch 7, Iteration: 293, Loss: 4.403707981109619\n",
      "Epoch 7, Iteration: 294, Loss: 4.281400203704834\n",
      "Epoch 7, Iteration: 295, Loss: 4.352046966552734\n",
      "Epoch 7, Iteration: 296, Loss: 4.451261520385742\n",
      "Epoch 7, Iteration: 297, Loss: 4.3779096603393555\n",
      "Epoch 7, Iteration: 298, Loss: 4.49993896484375\n",
      "Epoch 7, Iteration: 299, Loss: 4.310068607330322\n",
      "Epoch 7, Iteration: 300, Loss: 4.4056291580200195\n",
      "b\"I don't believe He sees the picture in his head in the distance. EXT. SPINNER - the wall off, pay from an invitation. Batty in his be obliged of a couple of a huge enlargement and the room at the wall in front between it with his the side DECKARD You can hear a few The Egyptian works Deckard steps cautiously in front between the door. DECKARD No. The Counterman nods, corrected Bryant's embrace. into view a little coals distinguished very well Spinner hits him but Leon's eye in the alley. Deckard turns in the alley. Deckard is standing studying it and\"\n",
      "Epoch 7, Iteration: 301, Loss: 4.2836222648620605\n",
      "Epoch 7, Iteration: 302, Loss: 4.4036784172058105\n",
      "Epoch 7, Iteration: 303, Loss: 4.289904594421387\n",
      "Epoch 7, Iteration: 304, Loss: 4.363861083984375\n",
      "Epoch 7, Iteration: 305, Loss: 4.397350788116455\n",
      "Epoch 7, Iteration: 306, Loss: 4.358825206756592\n",
      "Epoch 7, Iteration: 307, Loss: 4.2392048835754395\n",
      "Epoch 7, Iteration: 308, Loss: 4.235383987426758\n",
      "Epoch 7, Iteration: 309, Loss: 4.271188259124756\n",
      "Epoch 7, Iteration: 310, Loss: 4.188010215759277\n",
      "Epoch 7, Iteration: 311, Loss: 4.498166084289551\n",
      "Epoch 7, Iteration: 312, Loss: 4.320096492767334\n",
      "Epoch 7, Iteration: 313, Loss: 4.259096622467041\n",
      "Epoch 7, Iteration: 314, Loss: 4.367888450622559\n",
      "Epoch 7, Iteration: 315, Loss: 4.137643337249756\n",
      "Epoch 7, Iteration: 316, Loss: 4.376689434051514\n",
      "Epoch 7, Iteration: 317, Loss: 4.290964603424072\n",
      "Epoch 7, Iteration: 318, Loss: 4.264620304107666\n",
      "Epoch 7, Iteration: 319, Loss: 4.116493225097656\n",
      "Epoch 7, Iteration: 320, Loss: 4.18855619430542\n",
      "b\"I take the room at a lot a series through a few moments, CUT A fish Esper code lewd pulls as he shakes it with a lot of You are you get the side like fireworks and a little the picture on its recesses the edge with the edge to a shark's dirty of a lot in a lot in her eyes pour FIRE to be a shark's set. and the spinner zips you interesting, look looks like a long night missing from a little boy and puts them job of boiled dog. and a little boy - DAWN It's a shark's\"\n",
      "Epoch 7, Iteration: 321, Loss: 3.962136745452881\n",
      "Epoch 7, Iteration: 322, Loss: 4.05271053314209\n",
      "Epoch 7, Iteration: 323, Loss: 4.102382659912109\n",
      "Epoch 7, Iteration: 324, Loss: 4.0956339836120605\n",
      "Epoch 7, Iteration: 325, Loss: 4.192783355712891\n",
      "Epoch 7, Iteration: 326, Loss: 4.337682247161865\n",
      "Epoch 7, Iteration: 327, Loss: 4.262301445007324\n",
      "Epoch 7, Iteration: 328, Loss: 4.192349433898926\n",
      "Epoch 8, Iteration: 329, Loss: 4.2220048904418945\n",
      "Epoch 8, Iteration: 330, Loss: 4.157477855682373\n",
      "Epoch 8, Iteration: 331, Loss: 4.258601188659668\n",
      "Epoch 8, Iteration: 332, Loss: 4.007230281829834\n",
      "Epoch 8, Iteration: 333, Loss: 4.152317047119141\n",
      "Epoch 8, Iteration: 334, Loss: 4.23967981338501\n",
      "Epoch 8, Iteration: 335, Loss: 4.241689205169678\n",
      "Epoch 8, Iteration: 336, Loss: 4.2348737716674805\n",
      "Epoch 8, Iteration: 337, Loss: 4.358327865600586\n",
      "Epoch 8, Iteration: 338, Loss: 4.1684088706970215\n",
      "Epoch 8, Iteration: 339, Loss: 4.145401954650879\n",
      "Epoch 8, Iteration: 340, Loss: 4.0400004386901855\n",
      "b\"I don't his way that case, No choice, She's table from the floor. His face hurts. it is is the elevator is is standing in his hand is a snake pal. He opens he sees out a button. through a huge contact, there's an aquarium. combat know the floor. He sees a snake and holds Deckard steps five EGYPTIAN Yes. The Egyptian a long in a little coals athletic. His fingers is the Tyrell looks alarmed. up and a couple His voice drops into him. Batty leans close up at her. One environments. 3. her back, six and he feels at him.\"\n",
      "Epoch 8, Iteration: 341, Loss: 4.216916561126709\n",
      "Epoch 8, Iteration: 342, Loss: 4.1266279220581055\n",
      "Epoch 8, Iteration: 343, Loss: 4.204874038696289\n",
      "Epoch 8, Iteration: 344, Loss: 3.9571287631988525\n",
      "Epoch 8, Iteration: 345, Loss: 4.383970260620117\n",
      "Epoch 8, Iteration: 346, Loss: 4.444455146789551\n",
      "Epoch 8, Iteration: 347, Loss: 4.233922004699707\n",
      "Epoch 8, Iteration: 348, Loss: 4.209938049316406\n",
      "Epoch 8, Iteration: 349, Loss: 4.123837947845459\n",
      "Epoch 8, Iteration: 350, Loss: 4.186164379119873\n",
      "Epoch 8, Iteration: 351, Loss: 4.084384918212891\n",
      "Epoch 8, Iteration: 352, Loss: 4.433270454406738\n",
      "Epoch 8, Iteration: 353, Loss: 4.258932590484619\n",
      "Epoch 8, Iteration: 354, Loss: 4.166818141937256\n",
      "Epoch 8, Iteration: 355, Loss: 4.243472576141357\n",
      "Epoch 8, Iteration: 356, Loss: 4.3513407707214355\n",
      "Epoch 8, Iteration: 357, Loss: 4.179495811462402\n",
      "Epoch 8, Iteration: 358, Loss: 4.184184551239014\n",
      "Epoch 8, Iteration: 359, Loss: 4.187178134918213\n",
      "Epoch 8, Iteration: 360, Loss: 4.126283168792725\n",
      "b\"I guess you'd prefer things. BATTY What give the room lit etched. inside, you chickened The place in this sub-zero Chew tentative, It is a little night. Deckard is standing in his pocket. and looks for you? Batty is a long time to be jealous. LEON My... only the room at the stage room for you? Deckard and starts to an eerie distortion and starts picking Tears I take on his head loose you going? He starts through the picture to an eerie She's Dekcard directly itself I wouldn't let a long came comes unshaven. coat! NIGHT Small that at Tyrell. Tyrell\"\n",
      "Epoch 8, Iteration: 361, Loss: 4.043983459472656\n",
      "Epoch 8, Iteration: 362, Loss: 4.035434722900391\n",
      "Epoch 8, Iteration: 363, Loss: 3.8991708755493164\n",
      "Epoch 8, Iteration: 364, Loss: 4.100435733795166\n",
      "Epoch 8, Iteration: 365, Loss: 4.095836639404297\n",
      "Epoch 8, Iteration: 366, Loss: 4.187543869018555\n",
      "Epoch 8, Iteration: 367, Loss: 4.256453514099121\n",
      "Epoch 8, Iteration: 368, Loss: 4.174752712249756\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19555/3920611566.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Back-propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Gradient clipping (inline)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/github/repositories/Sphinxs/Linguistic/venv/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/github/repositories/Sphinxs/Linguistic/venv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "cd7201dc0387c8bd332ac6de9d30fde83ccdf6b5c00ebd7fe500da27331344d6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}